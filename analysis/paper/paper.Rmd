---
title: "Stickleback: a machine learning pipeline for detecting behavioral events in bio-logging data"
author:
  - Max Czapanskiy:
      email: maxczapanskiy@gmail.com
      institute: [SU]
      correspondence: true
  - Salma Abdel-Raheem:
      email: fl@another.edu
      institute: [WM]
      correspondence: false
  - Ariana Mann:
      email: ajmann@stanford.edu
      institute: [SU]
      correspondence: false
  - Nicole Nova:
      email: nicole.nova@stanford.edu
      institute: [SU]
      correspondence: false
  - Shirel Kahane-Rapport:
      email: skahane-rapport@fullerton.edu
      institute: [CSUF]
      correspondence: false
  - Jeremy Goldbogen:
      email: jergold@stanford.edu
      institute: [SU]
      correspondence: false
institute:
  - SU: Stanford University
  - WM: Whale Museum
  - CSUF: CSU Fullerton
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::word_document2:
      fig_caption: yes
      reference_docx: "../templates/template.docx" # Insert path for the DOCX file
      pandoc_args:
      - --lua-filter=../templates/scholarly-metadata.lua
      - --lua-filter=../templates/author-info-blocks.lua
      - --lua-filter=../templates/pagebreak.lua
bibliography: references.bib
zotero: stickleback
csl: "../templates/methods-in-ecology-and-evolution.csl" # Insert path for the bib-style
abstract: |
  Text of abstract
keywords: |
  keyword 1; keyword 2; keyword 3
---

<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

<!-- With the following code you can access and display values from the yml header above. -->

Keywords: `r rmarkdown::metadata$keywords`

<!-- The following code chunk defines some general settings how code chunks should behave. -->

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  comment = "#>",
  fig.path = "../figures/",
  dpi = 300
)
```

<!-- The actual document text starts here: -->

# Introduction

> It is... the experience of every good naturalist that the longer one studies a species, the more adaptive aspects of its behaviour one becomes aware of. The phenomena are countless, the field is practically unexplored, and yet without exploring it systematically we cannot hope to understand how behaviour helps animals to survive. [@tinbergen1963, p. 421]

High-resolution, multi-sensor bio-loggers push the limits of observable animal behavior, enabling biologists to pursue questions in new environments and spatio-temporal scales [@wilson2014; @williams2020]. While direct observation remains a powerful tool in ethology, new classes of animal-borne sensors, from inertial measurement units (IMUs) [@noda2014] to video cameras [@nakamura2015], can capture year-round animal behavior [@chimienti2021] in natural settings as remote as kilometers below [@shearer2019] and above the ocean [@weimerskirch2003]. Early bio-loggers collected perhaps a single data point, such as the dive duration of a seal [@williams2021]. Modern bio-loggers now collect vastly more complex data, with sample rates on the order of 10s to 1000s Hz, from multiple sensors, simultaneously. As the data revolution created new research opportunities, it also introduced new challenges for behavioral description. Researchers have relied on direct observation to understand the biological significance of complex animal behaviors, such as territory defense by sticklebacks [@tinbergen1951], social cohesion in marine mammals [@weinrich1991], and group hunting by lions [@stander1992]. But identification of even simple behaviors in bio-logging data remains an active area of research [@williams2017].

Fine-scale behaviors on the order of seconds often hold biological significance disproportionate to their brief duration. Such behaviors, which can be detected with bio-loggers, have allowed biologists to pursue key questions related to a behavior's mechanisms and current utility, and its effects on an organism's evolutionary history and development [@bateson2013]. For instance, consider the unique lunge-feeding behavior of rorqual whales (family Balaenopteridae) [@goldbogen2017]. The combination of IMUs with video cameras revealed this behavior's mechanisms [@cade2016; @kahane-rapport2020], its current utility in terms of energetic efficiency [@potvin2021], and why lunge-feeding whales evolved into the largest animals in the history of life on earth [@goldbogen2019]. In another study, researchers deployed acoustic biologgers to track the development of sperm whales' (*Physeter macrocephalus*) complex social behaviors and discovered that, unlike most terrestrial species, the ontogeny of sperm whale social behavior follows locomotor development [@tønnesen2018]. In addition to fundamental biological questions, fine-scale behaviors detected using bio-loggers have also been used to address applied conservation issues, such as the susceptibility of endangered species to climate change [@pagano2018]. Other applications include theoretical population biology [@wilson2018], natural history of cryptic predators [@studd2021], integrative physiology [@nakamura2015], and biomechanics [@sato2008].

Unlike behavioral state or mode classification, which typically relies on unsupervised learning methods (e.g., hidden markov models; @mcclintock2018; @leos-barajas2017), detection of discrete behaviors in bio-logging data is typically treated as a supervised learning problem [@chakravarty2020; @wilson2018]. Labeled behavior data for model training may be generated from animal-borne cameras [@watanabe2013], direct observation of captive animals [@pagano2017], or expert interpretation of sensor data [@gallon2013]. Modeling approaches include manually parameterized decision trees [@allen2016; @lagarde2008], signal processing [@sweeney2019], and machine learning algorithms like K-nearest neighbor [@bidder2020] and random forests [@pagano2017]. More recent methods combine multiple algorithms in hybrid models. Seek-and-learn, for example, first uses signal processing to identify behavior candidates, then refines predictions with a hierarchy of logistic regressions [@chakravarty2020]. Though bio-logging data are fundamentally time series, current machine learning approaches apply algorithms designed for tabular data. Discrete behaviors must therefore be represented as statistical summaries over short time windows; such as the mean, range, and standard deviation of sensor signals (and/or derived quantities e.g., dynamic body acceleration) [@pagano2017; @bidder2020]. These whole-series summaries lose the information contained in the order of the time series, which is why the Lowest Common Denominator (LoCoD) method uses a sequence of base elements (e.g., a step) as building blocks for matching more complex behaviors (e.g., walking) [@wilson2018].. LoCoD models are an improvement on earlier methods because they embrace, rather than erase, the temporal nature of behavior. However, they require substantial expertise and time to implement, and at present possess limited generalizability.

Time series classification (TSC) has been of great interest to data mining research, independent of animal behavior and bio-logging [@keogh2003]. Dozens of new algorithms have been published in recent years [@bagnall2017; @ruiz2021], fueled by a publicly available, standardized library of labeled time series [@UCRArchive], and made available to the broader scientific community through the `sktime` Python package [@löning2019]. Particularly relevant to the detection of animal behavior are interval-based TSC algorithms. These algorithms identify informative intervals within the larger time series using simple statistical transformations (e.g., slope and standard deviation) [@deng2013; @cabello2020; @middlehurst2020], analogous to the base elements of the LoCoD method. Consider the intervals that characterize the lunge-feeding behavior of rorquals. The animal (1) accelerates towards a prey aggregation, (2) reaching maximum speed before (3) it opens its mouth to engulf the prey, inducing a rapid deceleration, ending with (4) a prolonged low-speed period while the engulfed water is filtered through its baleen [@shadwick2019; @simon2012; @kahane-rapport2020]. In bio-logging data (a time series of speed, in this case), that sequence can be characterized as intervals with (1) a moderate positive slope (acceleration), (2) a high mean (maximum speed), (3) a steep negative slope (deceleration), and (4) a low mean (filtration). **Good place for a figure!** Interval-based TSC algorithms are apparently well suited to bio-logging data, but since behavior event detection is an *annotation* problem (finding events within a time series) rather than a *classification* problem (assigning a class to a whole time series), TSC algorithms must be adapted for this purpose.

We present a method, `stickleback` (named for the classic animal behavior model organism), that trains a machine learning pipeline to detect behavioral events in bio-logging data by incorporating TSC algorithms. The pipeline is algorithm agnostic, granting researchers flexibility in choosing specific machine learning algorithms. This modular approach provides a wide range of choices from existing TSC algorithms and facilitates incorporation of future methodological advances in TSC research. Using three behaviors across two taxa as case studies, we demonstrate how to: choose a TSC algorithm, fit a behavior detection model, make predictions on novel data, and assess model accuracy. `stickleback` is available in both Python and R packages.

# Materials and Methods

## `stickleback` pipeline

Fitting the `stickleback` pipeline takes three steps: a local step for training the TSC model on short time windows, a global step for applying the trained TSC model longitudinally, and a boosting step for reducing errors.

### Local step

The local step trains a two-class TSC model ('event' and 'non-event'). It takes as input: (i) a collection of bio-logging data (represented as data frames, where each column is a sensor-derived variable), (ii) a corresponding collection of behavioral event timestamps, (iii) a TSC algorithm for the local model [e.g. supervised time series forest @cabello2020 or canonical interval forest @middlehurst2020], and (iv) the size of the sliding window. A training dataset for the TSC model is generated by extracting windows from the the bio-logging data. This includes all windows centered on labeled events ('event') and an equal-sized random sample of non-overlapping windows ('non-event'). The local model is fitted to these training data.

### Global step

The global step identifies a threshold for converting local probabilities to a collection of predicted event timestamps. Its inputs are (i) the number of folds used for cross-validating the the threshold and (ii) a temporal tolerance for prediction accuracy. First, the global step generates a new time series (the local probability) by making longitudinal predictions with the local model using a sliding window. Predicted events are chosen from peaks in the local probability time series. Only peaks that exceed a *prominence* threshold (as opposed to height) are retained as predicted events, because peak prominence is more robust to noise than absolute height. The peak prominence threshold is chosen to maximize the overall $F_1$ (\@ref(eq:f1)) score using cross validation. For example, let the input consist of four bio-logger deployments with labeled events, two folds for cross validation, and a 1 s temporal tolerance. The global step divides the deployments into two folds (1-2, 3-4), fits the local step on each fold, and predicts the local probability of events in the other fold. The peak prominence threshold is then chosen by maximizing the $F_1$ score. For a candidate peak prominence threshold, all peaks below the threshold are removed. Each remaining peak is considered a true positive ($tp$) if it is the closest peak to a labeled event within the temporal tolerance, otherwise it's considered a false positive ($fp$). Labeled events with no peaks within the temporal tolerance are considered false negatives ($fn$).

```{=tex}
\begin{equation}
F_1=\frac{tp}{tp+\frac{1}{2}(fp+fn)} (\#eq:f1)
\end{equation}
```
### Boosting step

The pipeline is likely to produce substantial false positives after the first pass through the local and global steps because 'event' windows represented 50% of the local step training data but are probably a much smaller fraction of the longitudinal data. Since it is impossible to know *a priori* which 'non-event' windows contain information necessary for the local model to accurately detect 'events', we use a data-driven boosting step to improve prediction accuracy. After the first iteration of the local and global steps, the windows centered on false positive predictions are added to the local step training dataset, then the local and global steps are repeated.

# Results

# Discussion

# Conclusions

# Acknowledgments

# Conflict of Interest

# Data Availability

<!-- The following line inserts a page break  -->

\newpage

# References

<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->

::: {#refs}
:::

\newpage

### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies:

```{r colophon, cache = FALSE}
# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```
